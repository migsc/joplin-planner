"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.TestApp = exports.createNTestTags = exports.createNTestFolders = exports.createNTestNotes = exports.at = exports.sortedIds = exports.ids = exports.id = exports.currentClientId = exports.decryptionWorker = exports.fileContentEqual = exports.loadEncryptionMasterKey = exports.encryptionService = exports.checkThrow = exports.checkThrowAsync = exports.objectsEqual = exports.syncTargetId = exports.switchClient = exports.clearDatabase = exports.sleep = exports.fileApi = exports.synchronizer = exports.db = exports.setupDatabaseAndSynchronizer = exports.revisionService = exports.setupDatabase = exports.msleep = exports.allSyncTargetItemsEncrypted = exports.tempFilePath = exports.resourceFetcher = exports.resourceService = exports.expectNotThrow = exports.logger = exports.expectThrow = exports.kvStore = exports.isNetworkSyncTarget = exports.createTempDir = exports.syncDir = exports.setSyncTargetName = exports.syncTargetName = exports.afterEachCleanUp = exports.synchronizerStart = exports.exportDir = exports.afterAllCleanUp = exports.waitForFolderCount = exports.supportDir = exports.naughtyStrings = exports.createFolderTree = void 0;
/* eslint-disable require-atomic-updates */
const BaseApplication_1 = require("../BaseApplication");
const BaseModel_1 = require("../BaseModel");
const Logger_1 = require("../Logger");
const Setting_1 = require("../models/Setting");
const BaseService_1 = require("../services/BaseService");
const fs_driver_node_1 = require("../fs-driver-node");
const time_1 = require("../time");
const shim_1 = require("../shim");
const uuid_1 = require("../uuid");
const ResourceService_1 = require("../services/ResourceService");
const KeymapService_1 = require("../services/KeymapService");
const KvStore_1 = require("../services/KvStore");
const KeychainServiceDriver_node_1 = require("../services/keychain/KeychainServiceDriver.node");
const KeychainServiceDriver_dummy_1 = require("../services/keychain/KeychainServiceDriver.dummy");
const file_api_driver_joplinServer_1 = require("../file-api-driver-joplinServer");
const onedrive_api_1 = require("../onedrive-api");
const SyncTargetOneDrive_1 = require("../SyncTargetOneDrive");
const JoplinDatabase_1 = require("../JoplinDatabase");
const fs = require("fs-extra");
const { DatabaseDriverNode } = require('../database-driver-node.js');
const Folder_1 = require("../models/Folder");
const Note_1 = require("../models/Note");
const ItemChange_1 = require("../models/ItemChange");
const Resource_1 = require("../models/Resource");
const Tag_1 = require("../models/Tag");
const NoteTag_1 = require("../models/NoteTag");
const Revision_1 = require("../models/Revision");
const MasterKey_1 = require("../models/MasterKey");
const BaseItem_1 = require("../models/BaseItem");
const file_api_1 = require("../file-api");
const FileApiDriverMemory = require('../file-api-driver-memory').default;
const { FileApiDriverLocal } = require('../file-api-driver-local');
const { FileApiDriverWebDav } = require('../file-api-driver-webdav.js');
const { FileApiDriverDropbox } = require('../file-api-driver-dropbox.js');
const { FileApiDriverOneDrive } = require('../file-api-driver-onedrive.js');
const { FileApiDriverAmazonS3 } = require('../file-api-driver-amazon-s3.js');
const SyncTargetRegistry_1 = require("../SyncTargetRegistry");
const SyncTargetMemory = require('../SyncTargetMemory.js');
const SyncTargetFilesystem = require('../SyncTargetFilesystem.js');
const SyncTargetNextcloud = require('../SyncTargetNextcloud.js');
const SyncTargetDropbox = require('../SyncTargetDropbox.js');
const SyncTargetAmazonS3 = require('../SyncTargetAmazonS3.js');
const SyncTargetJoplinServer_1 = require("../SyncTargetJoplinServer");
const EncryptionService_1 = require("../services/e2ee/EncryptionService");
const DecryptionWorker_1 = require("../services/DecryptionWorker");
const RevisionService_1 = require("../services/RevisionService");
const ResourceFetcher_1 = require("../services/ResourceFetcher");
const WebDavApi = require('../WebDavApi');
const DropboxApi = require('../DropboxApi');
const JoplinServerApi_1 = require("../JoplinServerApi");
const credentialFiles_1 = require("../utils/credentialFiles");
const SyncTargetJoplinCloud_1 = require("../SyncTargetJoplinCloud");
const KeychainService_1 = require("../services/keychain/KeychainService");
const SettingUtils_1 = require("../services/SettingUtils");
const syncInfoUtils_1 = require("../services/synchronizer/syncInfoUtils");
const SyncTargetNone_1 = require("../SyncTargetNone");
const ppk_1 = require("../services/e2ee/ppk");
const md5 = require('md5');
const { S3Client } = require('@aws-sdk/client-s3');
const { Dirnames } = require('../services/synchronizer/utils/types');
const RSA_node_1 = require("../services/e2ee/RSA.node");
// Each suite has its own separate data and temp directory so that multiple
// suites can be run at the same time. suiteName is what is used to
// differentiate between suite and it is currently set to a random string
// (Ideally it would be something like the filename currently being executed by
// Jest, to make debugging easier, but it's not clear how to get this info).
const suiteName_ = uuid_1.default.createNano();
const databases_ = [];
let synchronizers_ = [];
const fileApis_ = {};
const encryptionServices_ = [];
const revisionServices_ = [];
const decryptionWorkers_ = [];
const resourceServices_ = [];
const resourceFetchers_ = [];
const kvStores_ = [];
let currentClient_ = 1;
// The line `process.on('unhandledRejection'...` in all the test files is going to
// make it throw this error. It's not too big a problem so disable it for now.
// https://stackoverflow.com/questions/9768444/possible-eventemitter-memory-leak-detected
process.setMaxListeners(0);
shim_1.default.setIsTestingEnv(true);
const fsDriver = new fs_driver_node_1.default();
Logger_1.default.fsDriver_ = fsDriver;
Resource_1.default.fsDriver_ = fsDriver;
EncryptionService_1.default.fsDriver_ = fsDriver;
FileApiDriverLocal.fsDriver_ = fsDriver;
// Most test units were historically under /app-cli so most test-related
// directories are there but that should be moved eventually under the right
// packages, or even out of the monorepo for temp files, logs, etc.
const oldTestDir = `${__dirname}/../../app-cli/tests`;
const logDir = `${oldTestDir}/logs`;
const baseTempDir = `${oldTestDir}/tmp/${suiteName_}`;
const supportDir = `${oldTestDir}/support`;
exports.supportDir = supportDir;
// We add a space in the data directory path as that will help uncover
// various space-in-path issues.
const dataDir = `${oldTestDir}/test data/${suiteName_}`;
const profileDir = `${dataDir}/profile`;
const rootProfileDir = profileDir;
fs.mkdirpSync(logDir);
fs.mkdirpSync(baseTempDir);
fs.mkdirpSync(dataDir);
fs.mkdirpSync(profileDir);
SyncTargetRegistry_1.default.addClass(SyncTargetNone_1.default);
SyncTargetRegistry_1.default.addClass(SyncTargetMemory);
SyncTargetRegistry_1.default.addClass(SyncTargetFilesystem);
SyncTargetRegistry_1.default.addClass(SyncTargetOneDrive_1.default);
SyncTargetRegistry_1.default.addClass(SyncTargetNextcloud);
SyncTargetRegistry_1.default.addClass(SyncTargetDropbox);
SyncTargetRegistry_1.default.addClass(SyncTargetAmazonS3);
SyncTargetRegistry_1.default.addClass(SyncTargetJoplinServer_1.default);
SyncTargetRegistry_1.default.addClass(SyncTargetJoplinCloud_1.default);
let syncTargetName_ = '';
let syncTargetId_ = null;
let sleepTime = 0;
let isNetworkSyncTarget_ = false;
function syncTargetName() {
    return syncTargetName_;
}
exports.syncTargetName = syncTargetName;
function setSyncTargetName(name) {
    if (name === syncTargetName_)
        return syncTargetName_;
    const previousName = syncTargetName_;
    syncTargetName_ = name;
    syncTargetId_ = SyncTargetRegistry_1.default.nameToId(syncTargetName_);
    sleepTime = syncTargetId_ === SyncTargetRegistry_1.default.nameToId('filesystem') ? 1001 : 100; // 400;
    isNetworkSyncTarget_ = ['nextcloud', 'dropbox', 'onedrive', 'amazon_s3', 'joplinServer'].includes(syncTargetName_);
    synchronizers_ = [];
    return previousName;
}
exports.setSyncTargetName = setSyncTargetName;
setSyncTargetName('memory');
// setSyncTargetName('filesystem');
// setSyncTargetName('nextcloud');
// setSyncTargetName('dropbox');
// setSyncTargetName('onedrive');
// setSyncTargetName('amazon_s3');
// setSyncTargetName('joplinServer');
// console.info(`Testing with sync target: ${syncTargetName_}`);
const syncDir = `${oldTestDir}/sync/${suiteName_}`;
exports.syncDir = syncDir;
// 90 seconds now that the tests are running in parallel and have been
// split into smaller suites might not be necessary but for now leave it
// anyway.
let defaultJestTimeout = 90 * 1000;
if (isNetworkSyncTarget_)
    defaultJestTimeout = 60 * 1000 * 10;
if (typeof jest !== 'undefined')
    jest.setTimeout(defaultJestTimeout);
const dbLogger = new Logger_1.default();
dbLogger.addTarget(Logger_1.TargetType.Console);
dbLogger.setLevel(Logger_1.default.LEVEL_WARN);
const logger = new Logger_1.default();
exports.logger = logger;
logger.addTarget(Logger_1.TargetType.Console);
logger.setLevel(Logger_1.LogLevel.Warn); // Set to DEBUG to display sync process in console
Logger_1.default.initializeGlobalLogger(logger);
BaseItem_1.default.loadClass('Note', Note_1.default);
BaseItem_1.default.loadClass('Folder', Folder_1.default);
BaseItem_1.default.loadClass('Resource', Resource_1.default);
BaseItem_1.default.loadClass('Tag', Tag_1.default);
BaseItem_1.default.loadClass('NoteTag', NoteTag_1.default);
BaseItem_1.default.loadClass('MasterKey', MasterKey_1.default);
BaseItem_1.default.loadClass('Revision', Revision_1.default);
Setting_1.default.setConstant('appId', 'net.cozic.joplintest-cli');
Setting_1.default.setConstant('appType', 'cli');
Setting_1.default.setConstant('tempDir', baseTempDir);
Setting_1.default.setConstant('cacheDir', baseTempDir);
Setting_1.default.setConstant('pluginDataDir', `${profileDir}/profile/plugin-data`);
Setting_1.default.setConstant('profileDir', profileDir);
Setting_1.default.setConstant('rootProfileDir', rootProfileDir);
Setting_1.default.setConstant('env', 'dev');
BaseService_1.default.logger_ = logger;
Setting_1.default.autoSaveEnabled = false;
function syncTargetId() {
    return syncTargetId_;
}
exports.syncTargetId = syncTargetId;
function isNetworkSyncTarget() {
    return isNetworkSyncTarget_;
}
exports.isNetworkSyncTarget = isNetworkSyncTarget;
function sleep(n) {
    return new Promise((resolve) => {
        shim_1.default.setTimeout(() => {
            resolve(null);
        }, Math.round(n * 1000));
    });
}
exports.sleep = sleep;
function msleep(ms) {
    // It seems setTimeout can sometimes last less time than the provided
    // interval:
    //
    // https://stackoverflow.com/a/50912029/561309
    //
    // This can cause issues in tests where we expect the actual duration to be
    // the same as the provided interval or more, but not less. So the code
    // below check that the elapsed time is no less than the provided interval,
    // and if it is, it waits a bit longer.
    const startTime = Date.now();
    return new Promise((resolve) => {
        shim_1.default.setTimeout(() => {
            if (Date.now() - startTime < ms) {
                const iid = setInterval(() => {
                    if (Date.now() - startTime >= ms) {
                        clearInterval(iid);
                        resolve(null);
                    }
                }, 2);
            }
            else {
                resolve(null);
            }
        }, ms);
    });
}
exports.msleep = msleep;
function currentClientId() {
    return currentClient_;
}
exports.currentClientId = currentClientId;
function afterEachCleanUp() {
    return __awaiter(this, void 0, void 0, function* () {
        yield ItemChange_1.default.waitForAllSaved();
        KeymapService_1.default.destroyInstance();
    });
}
exports.afterEachCleanUp = afterEachCleanUp;
function afterAllCleanUp() {
    return __awaiter(this, void 0, void 0, function* () {
        if (fileApi()) {
            try {
                yield fileApi().clearRoot();
            }
            catch (error) {
                console.warn('Could not clear sync target root:', error);
            }
        }
    });
}
exports.afterAllCleanUp = afterAllCleanUp;
const settingFilename = (id) => {
    return `settings-${id}.json`;
};
function switchClient(id, options = null) {
    return __awaiter(this, void 0, void 0, function* () {
        options = Object.assign({}, { keychainEnabled: false }, options);
        if (!databases_[id])
            throw new Error(`Call setupDatabaseAndSynchronizer(${id}) first!!`);
        yield time_1.default.msleep(sleepTime); // Always leave a little time so that updated_time properties don't overlap
        yield Setting_1.default.saveAll();
        currentClient_ = id;
        BaseModel_1.default.setDb(databases_[id]);
        BaseItem_1.default.encryptionService_ = encryptionServices_[id];
        Resource_1.default.encryptionService_ = encryptionServices_[id];
        BaseItem_1.default.revisionService_ = revisionServices_[id];
        yield Setting_1.default.reset();
        Setting_1.default.settingFilename = settingFilename(id);
        Setting_1.default.setConstant('profileDir', rootProfileDir);
        Setting_1.default.setConstant('rootProfileDir', rootProfileDir);
        Setting_1.default.setConstant('resourceDirName', resourceDirName(id));
        Setting_1.default.setConstant('resourceDir', resourceDir(id));
        Setting_1.default.setConstant('pluginDir', pluginDir(id));
        Setting_1.default.setConstant('isSubProfile', false);
        yield (0, SettingUtils_1.loadKeychainServiceAndSettings)(options.keychainEnabled ? KeychainServiceDriver_node_1.default : KeychainServiceDriver_dummy_1.default);
        Setting_1.default.setValue('sync.target', syncTargetId());
        Setting_1.default.setValue('sync.wipeOutFailSafe', false); // To keep things simple, always disable fail-safe unless explicitly set in the test itself
        // More generally, this function should clear all data, and so that should
        // include settings.json
        yield clearSettingFile(id);
    });
}
exports.switchClient = switchClient;
function clearDatabase(id = null) {
    return __awaiter(this, void 0, void 0, function* () {
        if (id === null)
            id = currentClient_;
        if (!databases_[id])
            return;
        yield ItemChange_1.default.waitForAllSaved();
        const tableNames = [
            'notes',
            'folders',
            'resources',
            'tags',
            'note_tags',
            'master_keys',
            'item_changes',
            'note_resources',
            'settings',
            'deleted_items',
            'sync_items',
            'notes_normalized',
            'revisions',
            'key_values',
        ];
        const queries = [];
        for (const n of tableNames) {
            queries.push(`DELETE FROM ${n}`);
            queries.push(`DELETE FROM sqlite_sequence WHERE name="${n}"`); // Reset autoincremented IDs
        }
        yield databases_[id].transactionExecBatch(queries);
    });
}
exports.clearDatabase = clearDatabase;
function setupDatabase(id = null, options = null) {
    return __awaiter(this, void 0, void 0, function* () {
        options = Object.assign({}, { keychainEnabled: false }, options);
        if (id === null)
            id = currentClient_;
        Setting_1.default.cancelScheduleSave();
        // Note that this was changed from `Setting.cache_ = []` to `await
        // Setting.reset()` during the TypeScript conversion. Normally this is
        // more correct but something to keep in mind anyway in case there are
        // some strange async issue related to settings when the tests are
        // running.
        yield Setting_1.default.reset();
        Setting_1.default.setConstant('profileDir', rootProfileDir);
        Setting_1.default.setConstant('rootProfileDir', rootProfileDir);
        Setting_1.default.setConstant('isSubProfile', false);
        if (databases_[id]) {
            BaseModel_1.default.setDb(databases_[id]);
            yield clearDatabase(id);
            yield (0, SettingUtils_1.loadKeychainServiceAndSettings)(options.keychainEnabled ? KeychainServiceDriver_node_1.default : KeychainServiceDriver_dummy_1.default);
            Setting_1.default.setValue('sync.target', syncTargetId());
            return;
        }
        const filePath = `${dataDir}/test-${id}.sqlite`;
        try {
            yield fs.unlink(filePath);
        }
        catch (error) {
            // Don't care if the file doesn't exist
        }
        databases_[id] = new JoplinDatabase_1.default(new DatabaseDriverNode());
        databases_[id].setLogger(dbLogger);
        yield databases_[id].open({ name: filePath });
        BaseModel_1.default.setDb(databases_[id]);
        yield clearSettingFile(id);
        yield (0, SettingUtils_1.loadKeychainServiceAndSettings)(options.keychainEnabled ? KeychainServiceDriver_node_1.default : KeychainServiceDriver_dummy_1.default);
        Setting_1.default.setValue('sync.target', syncTargetId());
    });
}
exports.setupDatabase = setupDatabase;
function clearSettingFile(id) {
    return __awaiter(this, void 0, void 0, function* () {
        Setting_1.default.settingFilename = `settings-${id}.json`;
        yield fs.remove(Setting_1.default.settingFilePath);
    });
}
function createFolderTree(parentId, tree, num = 0) {
    return __awaiter(this, void 0, void 0, function* () {
        let rootFolder = null;
        for (const item of tree) {
            const isFolder = !!item.children;
            num++;
            const data = Object.assign({}, item);
            delete data.children;
            if (isFolder) {
                const folder = yield Folder_1.default.save(Object.assign({ title: `Folder ${num}`, parent_id: parentId }, data));
                if (!rootFolder)
                    rootFolder = folder;
                if (item.children.length)
                    yield createFolderTree(folder.id, item.children, num);
            }
            else {
                yield Note_1.default.save(Object.assign({ title: `Note ${num}`, parent_id: parentId }, data));
            }
        }
        return rootFolder;
    });
}
exports.createFolderTree = createFolderTree;
function exportDir(id = null) {
    if (id === null)
        id = currentClient_;
    return `${dataDir}/export`;
}
exports.exportDir = exportDir;
function resourceDirName(id = null) {
    if (id === null)
        id = currentClient_;
    return `resources-${id}`;
}
function resourceDir(id = null) {
    if (id === null)
        id = currentClient_;
    return `${dataDir}/${resourceDirName(id)}`;
}
function pluginDir(id = null) {
    if (id === null)
        id = currentClient_;
    return `${dataDir}/plugins-${id}`;
}
function setupDatabaseAndSynchronizer(id, options = null) {
    return __awaiter(this, void 0, void 0, function* () {
        if (id === null)
            id = currentClient_;
        BaseService_1.default.logger_ = logger;
        yield setupDatabase(id, options);
        EncryptionService_1.default.instance_ = null;
        DecryptionWorker_1.default.instance_ = null;
        yield fs.remove(resourceDir(id));
        yield fs.mkdirp(resourceDir(id));
        yield fs.remove(pluginDir(id));
        yield fs.mkdirp(pluginDir(id));
        if (!synchronizers_[id]) {
            const SyncTargetClass = SyncTargetRegistry_1.default.classById(syncTargetId_);
            const syncTarget = new SyncTargetClass(db(id));
            yield initFileApi();
            syncTarget.setFileApi(fileApi());
            syncTarget.setLogger(logger);
            synchronizers_[id] = yield syncTarget.synchronizer();
            // For now unset the share service as it's not properly initialised.
            // Share service tests are in ShareService.test.ts normally, and if it
            // becomes necessary to test integration with the synchroniser we can
            // initialize it here.
            synchronizers_[id].setShareService(null);
        }
        encryptionServices_[id] = new EncryptionService_1.default();
        revisionServices_[id] = new RevisionService_1.default();
        decryptionWorkers_[id] = new DecryptionWorker_1.default();
        decryptionWorkers_[id].setEncryptionService(encryptionServices_[id]);
        resourceServices_[id] = new ResourceService_1.default();
        resourceFetchers_[id] = new ResourceFetcher_1.default(() => { return synchronizers_[id].api(); });
        kvStores_[id] = new KvStore_1.default();
        (0, ppk_1.setRSA)(RSA_node_1.default);
        yield fileApi().initialize();
        yield fileApi().clearRoot();
    });
}
exports.setupDatabaseAndSynchronizer = setupDatabaseAndSynchronizer;
function db(id = null) {
    if (id === null)
        id = currentClient_;
    return databases_[id];
}
exports.db = db;
function synchronizer(id = null) {
    if (id === null)
        id = currentClient_;
    return synchronizers_[id];
}
exports.synchronizer = synchronizer;
// This is like calling synchronizer.start() but it handles the
// complexity of passing around the sync context depending on
// the client.
function synchronizerStart(id = null, extraOptions = null) {
    return __awaiter(this, void 0, void 0, function* () {
        if (id === null)
            id = currentClient_;
        const contextKey = `sync.${syncTargetId()}.context`;
        const contextString = Setting_1.default.value(contextKey);
        const context = contextString ? JSON.parse(contextString) : {};
        const options = Object.assign({}, extraOptions);
        if (context)
            options.context = context;
        const newContext = yield synchronizer(id).start(options);
        Setting_1.default.setValue(contextKey, JSON.stringify(newContext));
        return newContext;
    });
}
exports.synchronizerStart = synchronizerStart;
function encryptionService(id = null) {
    if (id === null)
        id = currentClient_;
    return encryptionServices_[id];
}
exports.encryptionService = encryptionService;
function kvStore(id = null) {
    if (id === null)
        id = currentClient_;
    const o = kvStores_[id];
    o.setDb(db(id));
    return o;
}
exports.kvStore = kvStore;
function revisionService(id = null) {
    if (id === null)
        id = currentClient_;
    return revisionServices_[id];
}
exports.revisionService = revisionService;
function decryptionWorker(id = null) {
    if (id === null)
        id = currentClient_;
    const o = decryptionWorkers_[id];
    o.setKvStore(kvStore(id));
    return o;
}
exports.decryptionWorker = decryptionWorker;
function resourceService(id = null) {
    if (id === null)
        id = currentClient_;
    return resourceServices_[id];
}
exports.resourceService = resourceService;
function resourceFetcher(id = null) {
    if (id === null)
        id = currentClient_;
    return resourceFetchers_[id];
}
exports.resourceFetcher = resourceFetcher;
function loadEncryptionMasterKey(id = null, useExisting = false) {
    return __awaiter(this, void 0, void 0, function* () {
        const service = encryptionService(id);
        const password = '123456';
        let masterKey = null;
        if (!useExisting) { // Create it
            masterKey = yield service.generateMasterKey(password);
            masterKey = yield MasterKey_1.default.save(masterKey);
        }
        else { // Use the one already available
            const masterKeys = yield MasterKey_1.default.all();
            if (!masterKeys.length)
                throw new Error('No master key available');
            masterKey = masterKeys[0];
        }
        const passwordCache = Setting_1.default.value('encryption.passwordCache');
        passwordCache[masterKey.id] = password;
        Setting_1.default.setValue('encryption.passwordCache', passwordCache);
        yield Setting_1.default.saveAll();
        yield service.loadMasterKey(masterKey, password, true);
        (0, syncInfoUtils_1.setActiveMasterKeyId)(masterKey.id);
        return masterKey;
    });
}
exports.loadEncryptionMasterKey = loadEncryptionMasterKey;
function mustRunInBand() {
    if (!process.argv.includes('--runInBand')) {
        throw new Error('Tests must be run sequentially for this sync target, with the --runInBand arg. eg `yarn test --runInBand`');
    }
}
function initFileApi() {
    return __awaiter(this, void 0, void 0, function* () {
        if (fileApis_[syncTargetId_])
            return;
        let fileApi = null;
        if (syncTargetId_ === SyncTargetRegistry_1.default.nameToId('filesystem')) {
            fs.removeSync(syncDir);
            fs.mkdirpSync(syncDir);
            fileApi = new file_api_1.FileApi(syncDir, new FileApiDriverLocal());
        }
        else if (syncTargetId_ === SyncTargetRegistry_1.default.nameToId('memory')) {
            fileApi = new file_api_1.FileApi('/root', new FileApiDriverMemory());
        }
        else if (syncTargetId_ === SyncTargetRegistry_1.default.nameToId('nextcloud')) {
            const options = require(`${oldTestDir}/support/nextcloud-auth.json`);
            const api = new WebDavApi({
                baseUrl: () => options.baseUrl,
                username: () => options.username,
                password: () => options.password,
            });
            fileApi = new file_api_1.FileApi('', new FileApiDriverWebDav(api));
        }
        else if (syncTargetId_ === SyncTargetRegistry_1.default.nameToId('dropbox')) {
            // To get a token, go to the App Console:
            // https://www.dropbox.com/developers/apps/
            // Then select "JoplinTest" and click "Generated access token"
            const api = new DropboxApi();
            const authTokenPath = `${oldTestDir}/support/dropbox-auth.txt`;
            const authToken = fs.readFileSync(authTokenPath, 'utf8');
            if (!authToken)
                throw new Error(`Dropbox auth token missing in ${authTokenPath}`);
            api.setAuthToken(authToken);
            fileApi = new file_api_1.FileApi('', new FileApiDriverDropbox(api));
        }
        else if (syncTargetId_ === SyncTargetRegistry_1.default.nameToId('onedrive')) {
            // To get a token, open the URL below corresponding to your account type,
            // then copy the *complete* redirection URL in onedrive-auth.txt. Keep in mind that auth
            // data only lasts 1h for OneDrive.
            //
            // Personal OneDrive Account:
            // https://login.live.com/oauth20_authorize.srf?client_id=f1e68e1e-a729-4514-b041-4fdd5c7ac03a&scope=files.readwrite,offline_access&response_type=token&redirect_uri=https://joplinapp.org
            //
            // Business OneDrive Account:
            // https://login.microsoftonline.com/common/oauth2/v2.0/authorize?client_id=f1e68e1e-a729-4514-b041-4fdd5c7ac03a&scope=files.readwrite offline_access&response_type=token&redirect_uri=https://joplinapp.org
            //
            // Also for now OneDrive tests cannot be run in parallel because
            // for that each suite would need its own sub-directory within the
            // OneDrive app directory, and it's not clear how to get that
            // working.
            mustRunInBand();
            const { parameters, setEnvOverride } = require('../parameters.js');
            Setting_1.default.setConstant('env', 'dev');
            setEnvOverride('test');
            const config = parameters().oneDriveTest;
            const api = new onedrive_api_1.default(config.id, config.secret, false);
            const authData = fs.readFileSync(yield (0, credentialFiles_1.credentialFile)('onedrive-auth.txt'), 'utf8');
            const urlInfo = require('url-parse')(authData, true);
            const auth = require('querystring').parse(urlInfo.hash.substr(1));
            api.setAuth(auth);
            const accountProperties = yield api.execAccountPropertiesRequest();
            api.setAccountProperties(accountProperties);
            const appDir = yield api.appDirectory();
            fileApi = new file_api_1.FileApi(appDir, new FileApiDriverOneDrive(api));
        }
        else if (syncTargetId_ === SyncTargetRegistry_1.default.nameToId('amazon_s3')) {
            // We make sure for S3 tests run in band because tests
            // share the same directory which will cause locking errors.
            mustRunInBand();
            const amazonS3CredsPath = `${oldTestDir}/support/amazon-s3-auth.json`;
            const amazonS3Creds = require(amazonS3CredsPath);
            if (!amazonS3Creds || !amazonS3Creds.credentials)
                throw new Error(`AWS auth JSON missing in ${amazonS3CredsPath} format should be: { "credentials": { "accessKeyId": "", "secretAccessKey": "", } "bucket": "mybucket", region: "", forcePathStyle: ""}`);
            const api = new S3Client({ region: amazonS3Creds.region, credentials: amazonS3Creds.credentials, s3UseArnRegion: true, forcePathStyle: amazonS3Creds.forcePathStyle, endpoint: amazonS3Creds.endpoint });
            fileApi = new file_api_1.FileApi('', new FileApiDriverAmazonS3(api, amazonS3Creds.bucket));
        }
        else if (syncTargetId_ === SyncTargetRegistry_1.default.nameToId('joplinServer')) {
            mustRunInBand();
            const joplinServerAuth = JSON.parse(yield (0, credentialFiles_1.readCredentialFile)('joplin-server-test-units-2.json'));
            // const joplinServerAuth = {
            //     "email": "admin@localhost",
            //     "password": "admin",
            //     "baseUrl": "http://api.joplincloud.local:22300",
            //     "userContentBaseUrl": ""
            // }
            // Note that to test the API in parallel mode, you need to use Postgres
            // as database, as the SQLite database is not reliable when being
            // read/write from multiple processes at the same time.
            const api = new JoplinServerApi_1.default({
                baseUrl: () => joplinServerAuth.baseUrl,
                userContentBaseUrl: () => joplinServerAuth.userContentBaseUrl,
                username: () => joplinServerAuth.email,
                password: () => joplinServerAuth.password,
            });
            fileApi = new file_api_1.FileApi('', new file_api_driver_joplinServer_1.default(api));
        }
        fileApi.setLogger(logger);
        fileApi.setSyncTargetId(syncTargetId_);
        fileApi.setTempDirName(Dirnames.Temp);
        fileApi.requestRepeatCount_ = isNetworkSyncTarget_ ? 1 : 0;
        fileApis_[syncTargetId_] = fileApi;
    });
}
function fileApi() {
    return fileApis_[syncTargetId_];
}
exports.fileApi = fileApi;
function objectsEqual(o1, o2) {
    if (Object.getOwnPropertyNames(o1).length !== Object.getOwnPropertyNames(o2).length)
        return false;
    for (const n in o1) {
        if (!o1.hasOwnProperty(n))
            continue;
        if (o1[n] !== o2[n])
            return false;
    }
    return true;
}
exports.objectsEqual = objectsEqual;
function checkThrowAsync(asyncFn) {
    return __awaiter(this, void 0, void 0, function* () {
        let hasThrown = false;
        try {
            yield asyncFn();
        }
        catch (error) {
            hasThrown = true;
        }
        return hasThrown;
    });
}
exports.checkThrowAsync = checkThrowAsync;
function expectThrow(asyncFn, errorCode = undefined) {
    return __awaiter(this, void 0, void 0, function* () {
        let hasThrown = false;
        let thrownError = null;
        try {
            yield asyncFn();
        }
        catch (error) {
            hasThrown = true;
            thrownError = error;
        }
        if (!hasThrown) {
            expect('not throw').toBe('throw');
        }
        else if (thrownError.code !== errorCode) {
            console.error(thrownError);
            expect(`error code: ${thrownError.code}`).toBe(`error code: ${errorCode}`);
        }
        else {
            expect(true).toBe(true);
        }
    });
}
exports.expectThrow = expectThrow;
function expectNotThrow(asyncFn) {
    return __awaiter(this, void 0, void 0, function* () {
        let thrownError = null;
        try {
            yield asyncFn();
        }
        catch (error) {
            thrownError = error;
        }
        if (thrownError) {
            console.error(thrownError);
            expect(thrownError.message).toBe('');
        }
        else {
            expect(true).toBe(true);
        }
    });
}
exports.expectNotThrow = expectNotThrow;
function checkThrow(fn) {
    let hasThrown = false;
    try {
        fn();
    }
    catch (error) {
        hasThrown = true;
    }
    return hasThrown;
}
exports.checkThrow = checkThrow;
function fileContentEqual(path1, path2) {
    const fs = require('fs-extra');
    const content1 = fs.readFileSync(path1, 'base64');
    const content2 = fs.readFileSync(path2, 'base64');
    return content1 === content2;
}
exports.fileContentEqual = fileContentEqual;
function allSyncTargetItemsEncrypted() {
    return __awaiter(this, void 0, void 0, function* () {
        const list = yield fileApi().list('', { includeDirs: false });
        const files = list.items;
        let totalCount = 0;
        let encryptedCount = 0;
        for (let i = 0; i < files.length; i++) {
            const file = files[i];
            if (!BaseItem_1.default.isSystemPath(file.path))
                continue;
            const remoteContentString = yield fileApi().get(file.path);
            const remoteContent = yield BaseItem_1.default.unserialize(remoteContentString);
            const ItemClass = BaseItem_1.default.itemClass(remoteContent);
            if (!ItemClass.encryptionSupported())
                continue;
            totalCount++;
            if (remoteContent.type_ === BaseModel_1.default.TYPE_RESOURCE) {
                const content = yield fileApi().get(`.resource/${remoteContent.id}`);
                totalCount++;
                if (content.substr(0, 5) === 'JED01')
                    encryptedCount++;
            }
            if (remoteContent.encryption_applied)
                encryptedCount++;
        }
        if (!totalCount)
            throw new Error('No encryptable item on sync target');
        return totalCount === encryptedCount;
    });
}
exports.allSyncTargetItemsEncrypted = allSyncTargetItemsEncrypted;
function id(a) {
    return a.id;
}
exports.id = id;
function ids(a) {
    return a.map(n => n.id);
}
exports.ids = ids;
function sortedIds(a) {
    return ids(a).sort();
}
exports.sortedIds = sortedIds;
function at(a, indexes) {
    const out = [];
    for (let i = 0; i < indexes.length; i++) {
        out.push(a[indexes[i]]);
    }
    return out;
}
exports.at = at;
function createNTestFolders(n) {
    return __awaiter(this, void 0, void 0, function* () {
        const folders = [];
        for (let i = 0; i < n; i++) {
            const folder = yield Folder_1.default.save({ title: 'folder' });
            folders.push(folder);
            yield time_1.default.msleep(10);
        }
        return folders;
    });
}
exports.createNTestFolders = createNTestFolders;
function createNTestNotes(n, folder, tagIds = null, title = 'note') {
    return __awaiter(this, void 0, void 0, function* () {
        const notes = [];
        for (let i = 0; i < n; i++) {
            const title_ = n > 1 ? `${title}${i}` : title;
            const note = yield Note_1.default.save({ title: title_, parent_id: folder.id, is_conflict: 0 });
            notes.push(note);
            yield time_1.default.msleep(10);
        }
        if (tagIds) {
            for (let i = 0; i < notes.length; i++) {
                yield Tag_1.default.setNoteTagsByIds(notes[i].id, tagIds);
                yield time_1.default.msleep(10);
            }
        }
        return notes;
    });
}
exports.createNTestNotes = createNTestNotes;
function createNTestTags(n) {
    return __awaiter(this, void 0, void 0, function* () {
        const tags = [];
        for (let i = 0; i < n; i++) {
            const tag = yield Tag_1.default.save({ title: 'tag' });
            tags.push(tag);
            yield time_1.default.msleep(10);
        }
        return tags;
    });
}
exports.createNTestTags = createNTestTags;
function tempFilePath(ext) {
    return `${Setting_1.default.value('tempDir')}/${md5(Date.now() + Math.random())}.${ext}`;
}
exports.tempFilePath = tempFilePath;
function createTempDir() {
    return __awaiter(this, void 0, void 0, function* () {
        const tempDirPath = `${baseTempDir}/${uuid_1.default.createNano()}`;
        yield fs.mkdirp(tempDirPath);
        return tempDirPath;
    });
}
exports.createTempDir = createTempDir;
function waitForFolderCount(count) {
    return __awaiter(this, void 0, void 0, function* () {
        const timeout = 2000;
        const startTime = Date.now();
        while (true) {
            const folders = yield Folder_1.default.all();
            if (folders.length >= count)
                return;
            if (Date.now() - startTime > timeout)
                throw new Error('Timeout waiting for folders to be created');
            yield msleep(10);
        }
    });
}
exports.waitForFolderCount = waitForFolderCount;
let naughtyStrings_ = null;
function naughtyStrings() {
    return __awaiter(this, void 0, void 0, function* () {
        if (naughtyStrings_)
            return naughtyStrings_;
        const t = yield fs.readFile(`${supportDir}/big-list-of-naughty-strings.txt`, 'utf8');
        const lines = t.split('\n');
        naughtyStrings_ = [];
        for (const line of lines) {
            const trimmed = line.trim();
            if (!trimmed)
                continue;
            if (trimmed.indexOf('#') === 0)
                continue;
            naughtyStrings_.push(line);
        }
        return naughtyStrings_;
    });
}
exports.naughtyStrings = naughtyStrings;
// TODO: Update for Jest
// function mockDate(year, month, day, tick) {
// 	const fixedDate = new Date(2020, 0, 1);
// 	jasmine.clock().install();
// 	jasmine.clock().mockDate(fixedDate);
// }
// function restoreDate() {
// 	jasmine.clock().uninstall();
// }
// Application for feature integration testing
class TestApp extends BaseApplication_1.default {
    constructor(hasGui = true) {
        KeychainService_1.default.instance().enabled = false;
        super();
        this.hasGui_ = hasGui;
        this.middlewareCalls_ = [];
        this.logger_ = super.logger();
    }
    hasGui() {
        return this.hasGui_;
    }
    start(argv) {
        const _super = Object.create(null, {
            start: { get: () => super.start }
        });
        return __awaiter(this, void 0, void 0, function* () {
            this.logger_.info('Test app starting...');
            if (!argv.includes('--profile')) {
                argv = argv.concat(['--profile', `tests-build/profile/${uuid_1.default.create()}`]);
            }
            argv = yield _super.start.call(this, ['', ''].concat(argv));
            // For now, disable sync and encryption to avoid spurious intermittent failures
            // caused by them interupting processing and causing delays.
            Setting_1.default.setValue('sync.interval', 0);
            (0, syncInfoUtils_1.setEncryptionEnabled)(true);
            this.initRedux();
            Setting_1.default.dispatchUpdateAll();
            yield ItemChange_1.default.waitForAllSaved();
            yield this.wait();
            this.logger_.info('Test app started...');
        });
    }
    generalMiddleware(store, next, action) {
        const _super = Object.create(null, {
            generalMiddleware: { get: () => super.generalMiddleware }
        });
        return __awaiter(this, void 0, void 0, function* () {
            this.middlewareCalls_.push(true);
            try {
                yield _super.generalMiddleware.call(this, store, next, action);
            }
            finally {
                this.middlewareCalls_.pop();
            }
        });
    }
    wait() {
        return __awaiter(this, void 0, void 0, function* () {
            return new Promise((resolve) => {
                const iid = shim_1.default.setInterval(() => {
                    if (!this.middlewareCalls_.length) {
                        clearInterval(iid);
                        resolve(null);
                    }
                }, 100);
            });
        });
    }
    profileDir() {
        return __awaiter(this, void 0, void 0, function* () {
            return Setting_1.default.value('profileDir');
        });
    }
    destroy() {
        const _super = Object.create(null, {
            destroy: { get: () => super.destroy }
        });
        return __awaiter(this, void 0, void 0, function* () {
            this.logger_.info('Test app stopping...');
            yield this.wait();
            yield ItemChange_1.default.waitForAllSaved();
            this.deinitRedux();
            yield _super.destroy.call(this);
            yield time_1.default.msleep(100);
        });
    }
}
exports.TestApp = TestApp;
//# sourceMappingURL=test-utils.js.map