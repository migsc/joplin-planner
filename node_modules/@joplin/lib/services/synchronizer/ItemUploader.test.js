"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
const BaseItem_1 = require("../../models/BaseItem");
const Note_1 = require("../../models/Note");
const test_utils_1 = require("../../testing/test-utils");
const time_1 = require("../../time");
const ItemUploader_1 = require("./ItemUploader");
function clearArray(a) {
    a.splice(0, a.length);
}
function newFakeApi() {
    return { supportsMultiPut: true };
}
function newFakeApiCall(callRecorder, itemBodyCallback = null) {
    const apiCall = (callName, ...args) => __awaiter(this, void 0, void 0, function* () {
        callRecorder.push({ name: callName, args });
        if (callName === 'multiPut') {
            const [batch] = args;
            const output = { items: {} };
            for (const item of batch) {
                if (itemBodyCallback) {
                    output.items[item.name] = itemBodyCallback(item);
                }
                else {
                    output.items[item.name] = {
                        item: item.body,
                        error: null,
                    };
                }
            }
            return output;
        }
    });
    return apiCall;
}
describe('synchronizer/ItemUploader', function () {
    beforeEach((done) => __awaiter(this, void 0, void 0, function* () {
        yield (0, test_utils_1.setupDatabaseAndSynchronizer)(1);
        yield (0, test_utils_1.setupDatabaseAndSynchronizer)(2);
        yield (0, test_utils_1.switchClient)(1);
        done();
    }));
    it('should batch uploads and use the cache afterwards', (() => __awaiter(this, void 0, void 0, function* () {
        const callRecorder = [];
        const itemUploader = new ItemUploader_1.default(newFakeApi(), newFakeApiCall(callRecorder));
        const notes = [
            yield Note_1.default.save({ title: '1' }),
            yield Note_1.default.save({ title: '2' }),
        ];
        yield itemUploader.preUploadItems(notes);
        // There should be only one call to "multiPut" because the items have
        // been batched.
        expect(callRecorder.length).toBe(1);
        expect(callRecorder[0].name).toBe('multiPut');
        clearArray(callRecorder);
        // Now if we try to upload the item it shouldn't call the API because it
        // will use the cached item.
        yield itemUploader.serializeAndUploadItem(Note_1.default, BaseItem_1.default.systemPath(notes[0]), notes[0]);
        expect(callRecorder.length).toBe(0);
        // Now try to process a note that hasn't been cached. In that case, it
        // should call "PUT" directly.
        const note3 = yield Note_1.default.save({ title: '3' });
        yield itemUploader.serializeAndUploadItem(Note_1.default, BaseItem_1.default.systemPath(note3), note3);
        expect(callRecorder.length).toBe(1);
        expect(callRecorder[0].name).toBe('put');
    })));
    it('should not batch upload if the items are over the batch size limit', (() => __awaiter(this, void 0, void 0, function* () {
        const callRecorder = [];
        const itemUploader = new ItemUploader_1.default(newFakeApi(), newFakeApiCall(callRecorder));
        itemUploader.maxBatchSize = 1;
        const notes = [
            yield Note_1.default.save({ title: '1' }),
            yield Note_1.default.save({ title: '2' }),
        ];
        yield itemUploader.preUploadItems(notes);
        expect(callRecorder.length).toBe(0);
    })));
    it('should not use the cache if the note has changed since the pre-upload', (() => __awaiter(this, void 0, void 0, function* () {
        const callRecorder = [];
        const itemUploader = new ItemUploader_1.default(newFakeApi(), newFakeApiCall(callRecorder));
        const notes = [
            yield Note_1.default.save({ title: '1' }),
            yield Note_1.default.save({ title: '2' }),
        ];
        yield itemUploader.preUploadItems(notes);
        clearArray(callRecorder);
        yield itemUploader.serializeAndUploadItem(Note_1.default, BaseItem_1.default.systemPath(notes[0]), notes[0]);
        expect(callRecorder.length).toBe(0);
        yield time_1.default.msleep(1);
        notes[1] = yield Note_1.default.save({ title: '22' }),
            yield itemUploader.serializeAndUploadItem(Note_1.default, BaseItem_1.default.systemPath(notes[1]), notes[1]);
        expect(callRecorder.length).toBe(1);
    })));
    it('should respect the max batch size', (() => __awaiter(this, void 0, void 0, function* () {
        const callRecorder = [];
        const itemUploader = new ItemUploader_1.default(newFakeApi(), newFakeApiCall(callRecorder));
        const notes = [
            yield Note_1.default.save({ title: '1' }),
            yield Note_1.default.save({ title: '2' }),
            yield Note_1.default.save({ title: '3' }),
        ];
        const noteSize = BaseItem_1.default.systemPath(notes[0]).length + (yield Note_1.default.serializeForSync(notes[0])).length;
        itemUploader.maxBatchSize = noteSize * 2;
        // It should send two batches - one with two notes, and the second with
        // only one note.
        yield itemUploader.preUploadItems(notes);
        expect(callRecorder.length).toBe(2);
        expect(callRecorder[0].args[0].length).toBe(2);
        expect(callRecorder[1].args[0].length).toBe(1);
    })));
    it('should rethrow error for items within the batch', (() => __awaiter(this, void 0, void 0, function* () {
        const callRecorder = [];
        const notes = [
            yield Note_1.default.save({ title: '1' }),
            yield Note_1.default.save({ title: '2' }),
            yield Note_1.default.save({ title: '3' }),
        ];
        // Simulates throwing an error on note 2
        const itemBodyCallback = (item) => {
            if (item.name === BaseItem_1.default.systemPath(notes[1])) {
                return { error: new Error('Could not save item'), item: null };
            }
            else {
                return { error: null, item: item.body };
            }
        };
        const itemUploader = new ItemUploader_1.default(newFakeApi(), newFakeApiCall(callRecorder, itemBodyCallback));
        yield itemUploader.preUploadItems(notes);
        yield (0, test_utils_1.expectNotThrow)(() => __awaiter(this, void 0, void 0, function* () { return itemUploader.serializeAndUploadItem(Note_1.default, BaseItem_1.default.systemPath(notes[0]), notes[0]); }));
        yield (0, test_utils_1.expectThrow)(() => __awaiter(this, void 0, void 0, function* () { return itemUploader.serializeAndUploadItem(Note_1.default, BaseItem_1.default.systemPath(notes[1]), notes[1]); }));
        yield (0, test_utils_1.expectNotThrow)(() => __awaiter(this, void 0, void 0, function* () { return itemUploader.serializeAndUploadItem(Note_1.default, BaseItem_1.default.systemPath(notes[2]), notes[2]); }));
    })));
});
//# sourceMappingURL=ItemUploader.test.js.map